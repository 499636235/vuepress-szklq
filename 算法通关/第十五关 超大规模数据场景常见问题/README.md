# 第十五关｜超大规模数据场景常见问题

在大部分算法中，默认给定的数据量都很小的，例如只有几个或者十几个元素，但是如果将数据量提高到百万甚至十几亿，那处理逻辑就会发生很大差异，这也是算法考查中，经常出现的一类问题。此时普通的数组、链表、Hash、树等等结构有无效了 ，因为内存空间放不下了。而常规的递归、排序，回溯、贪心和动态规划等思想也无效了，因为执行都会超时，必须另外想办法。这类问题该如何下手呢？这里介绍三种非常典型的思路：
1.使用位存储，使用位存储最大的好处是占用的空间更小。一个字节占8个位，而在java里一个整数是4个字节 ，所以如果采用位存储，那占用空间是简单存整数的1/32。例如一个40亿的整数数组，如果用整数存储需要16GB左右的空间，而如果使用位存储，就可以用0.5GB的空间，这样很多问题就能够使用有限的内存来解决了。 
2.如果文件实在太大 ，无法在内存中放下，则需要考虑将大文件分成若干小块，先处理每个块，最后再逐步得到想要的结果，这种方式也叫做外部排序。这样需要遍历全部序列至少两次，是典型的用时间换空间的方法，详细请看题目1.2中的进阶问题、1.3、1.4和1.5小节。
3.堆，如果在超大数据中找第K大、第K小，K个最大、K个最小，则特别适合使用堆来做。而且将超大数据换成流数据也可以，而且几乎是唯一的方式，口诀就是“查小用大堆，查大用小堆”，